{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T17:26:18.971781Z",
     "start_time": "2020-01-16T17:26:18.950864Z"
    }
   },
   "outputs": [],
   "source": [
    "# Genetic Algorithm Class for hyperparamter optimisation\n",
    "#          generate_inital_popuilation()\n",
    "#          select()\n",
    "#          mate()\n",
    "#          mutate()\n",
    "#          evaluate()\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import kf_ml_lib as kf\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "class kf_genetic_algorithm:\n",
    "    def __init__(self, classifier, dataset_path, population_size, generations):\n",
    "        self.classifier = classifier\n",
    "        self.population_size = population_size\n",
    "        self.generations = generations\n",
    "        \n",
    "        # Gene pool\n",
    "        # Set options and constraints for the selected classifier's hyperparameters\n",
    "        if self.classifier == \"DecisionTreeClassifier\":\n",
    "            self.criterions = ['gini', 'entropy']\n",
    "            self.splits = ['best', 'random']\n",
    "            self.min_samples_splits = dict(low = 2, high = 5)\n",
    "            self.min_samples_leafs = dict(low = 0.0, high = 0.5)\n",
    "            self.min_weight_fraction_leafs = dict(low = 0, high = 0.5)\n",
    "            self.class_weights = ['balanced', None]\n",
    "                \n",
    "        # Generate inital chromosome population, with size population_size\n",
    "        self.population = self.generate_inital_population()\n",
    "        \n",
    "        # Load, process and split dataset\n",
    "        self.dataset = kf.load_dataset(dataset_path)\n",
    "        self.X, self.y = kf.split_dataset(self.dataset, extended=False)\n",
    "\n",
    "        self.y = np.split(self.y, 1)\n",
    "        self.y = np.array(self.y)\n",
    "        self.y = self.y.reshape(len(self.y[0]), 1)\n",
    "\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, train_size=0.7, stratify=self.y)\n",
    "        \n",
    "    \n",
    "    def __del__(self):\n",
    "        print(\"\\nDestroying ga object\\n\")\n",
    "\n",
    "        \n",
    "    # Function to generate an inital random population of chromosomes, given a population_size\n",
    "    def generate_inital_population(self):\n",
    "        print(\"Generating Population of size: \", self.population_size)\n",
    "        \n",
    "        # Inital chromosome population\n",
    "        population = []\n",
    "        \n",
    "        # Fill each chromosome with randomly selected genes from the gene pools and add it to the population\n",
    "        for i in range(0, self.population_size):\n",
    "            chromosome = []\n",
    "            chromosome.append(random.choice(self.criterions))\n",
    "            chromosome.append(random.choice(self.splits))\n",
    "            chromosome.append(random.randrange(self.min_samples_splits['low'], self.min_samples_splits['high']))\n",
    "            chromosome.append(random.uniform(self.min_samples_leafs['low'], self.min_samples_leafs['high']))\n",
    "            chromosome.append(random.uniform(self.min_weight_fraction_leafs['low'], self.min_weight_fraction_leafs['high']))   \n",
    "            chromosome.append(random.choice(self.class_weights))\n",
    "            \n",
    "            population.append(chromosome)\n",
    "        \n",
    "        return population\n",
    "\n",
    "    \n",
    "    # Run the Genetic Algorithm for N generations\n",
    "    def run(self):        \n",
    "        #for generation in range(0, generations):\n",
    "        \n",
    "        # Generate fitness scores for all the chromosomes in the population\n",
    "        fitness_scores = self.evaluate()           \n",
    "\n",
    "        # Select the best two performing chromosomes to be parents\n",
    "        parent1, parent2 = self.selection(fitness_scores)\n",
    "\n",
    "        # Mate parents using one-point-crossover in order to generate offspring\n",
    "        offspring1, offspring2 = self.crossover(parent1, parent2)\n",
    "        \n",
    "        # Mutate the offspring, selected at random, into the remaining population spaces\n",
    "        # REMAINING POPULATION SPACES!!! IMPORTANT\n",
    "        # use something like:\n",
    "        #        self.population = []\n",
    "        #        self.population = [parent1, parent2, offspring1, offspring2]\n",
    "        #        remaining_pop_space = self.population_size - len(self.population)\n",
    "        #\n",
    "        #        mutate(remaining_pop_space)\n",
    "        # \n",
    "        #        def mutate(remaining_pop_space):\n",
    "        #            for chromosome in remaining_pop_space:\n",
    "        #                  chromosome = self.population[3]\n",
    "        #                  \n",
    "        #                   # select random int to index a gene to mutate\n",
    "        #                   # then must mutate depending upon the chromosome's gene index, relating to the gene pool\n",
    "        #\n",
    "        #                   append chromosome to the self.population\n",
    "\n",
    "        # return best_result\n",
    "        \n",
    "    \n",
    "    # Generate fitness_scores for the given population\n",
    "    def evaluate(self):\n",
    "        fitness_scores = []\n",
    "        \n",
    "        for chromosome in self.population:\n",
    "            dtc = DecisionTreeClassifier(criterion=chromosome[0],\n",
    "                                         splitter=chromosome[1],\n",
    "                                         min_samples_split=chromosome[2],\n",
    "                                         min_samples_leaf=chromosome[3],\n",
    "                                         min_weight_fraction_leaf=chromosome[4],\n",
    "                                         class_weight=chromosome[5])\n",
    "            \n",
    "            dtc = dtc.fit(self.X_train, self.y_train)\n",
    "            \n",
    "            # Make predictions on test data for this chromosome\n",
    "            predictions = dtc.predict(self.X_test)\n",
    "            \n",
    "            # Evaluate model Precision, Recall and F1-Score performance\n",
    "            precision = metrics.precision_score(self.y_test, predictions, pos_label='Botnet')\n",
    "            recall = metrics.recall_score(self.y_test, predictions, pos_label='Botnet')\n",
    "            f1_score = kf.calc_f1_score(precision, recall)\n",
    "\n",
    "            fitness_scores.append(f1_score)\n",
    "    \n",
    "        return fitness_scores\n",
    "    \n",
    "    # Perform tournament selection on the evaluated chromosomes; returning the two best performers\n",
    "    def selection(self, fitness_scores):        \n",
    "        # Sort, from highest to lowest, the fitness_scores and their chromosomes\n",
    "        sorted_results = sorted(zip(fitness_scores, self.population), key=lambda x: x[0], reverse=True)\n",
    "        \n",
    "        # Remove 'nan' fitness_value results from the sorted_results\n",
    "        for result in sorted_results:\n",
    "            if np.isnan(result[0]):\n",
    "                sorted_results.remove(result)\n",
    "        \n",
    "        print(sorted_results)\n",
    "        \n",
    "        parent1 = sorted_results[0]\n",
    "        parent2 = sorted_results[1]\n",
    "        \n",
    "        print(\"Parent 1 = \", parent1)\n",
    "        print(\"Parent 2 = \", parent2)\n",
    "        \n",
    "        # KYLE-_A\n",
    "        # REMOVE FITNESS SCORES FROM THE CHROMOSOMES I.E UNZIP THEM FROM THE FITNESSS SCORES\n",
    "        \n",
    "        return parent1, parent2\n",
    "        \n",
    "    # Performs one-point-crossover of the parents, returning \n",
    "    def crossover(self, parent1, parent2):\n",
    "        \n",
    "        # KYLE TODO\n",
    "        #     REMOVE THE FITNESS SCORE FROM PARENT1 AND PARENT2 \n",
    "        #     IN THE SELECTION() FUNCTION BEFORE THEY ARE RETURNED!!!\n",
    "        #          SEE 'KYLE-_A'\n",
    "        \n",
    "        print(\"\\n\\nCrossover:\")\n",
    "        print(parent1)\n",
    "        print(parent2)\n",
    "        \n",
    "        return offspring1, offspring2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T17:26:41.759813Z",
     "start_time": "2020-01-16T17:26:19.436325Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Population of size:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\asmarus\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "G:\\USB Drive Files\\Year 3\\Semester 1\\KV6003 - Individual Computing Project\\Machine Learning\\kf_ml_lib.py:91: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  f1_score = 2 * ((precision*recall) / (precision+recall))\n",
      "c:\\users\\asmarus\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "G:\\USB Drive Files\\Year 3\\Semester 1\\KV6003 - Individual Computing Project\\Machine Learning\\kf_ml_lib.py:91: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  f1_score = 2 * ((precision*recall) / (precision+recall))\n",
      "c:\\users\\asmarus\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "G:\\USB Drive Files\\Year 3\\Semester 1\\KV6003 - Individual Computing Project\\Machine Learning\\kf_ml_lib.py:91: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  f1_score = 2 * ((precision*recall) / (precision+recall))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.6880424580228744, ['gini', 'best', 4, 0.1323130716702775, 0.1511691212720258, 'balanced']), (0.6506608391085034, ['entropy', 'best', 2, 0.3055614891036466, 0.068207406701416, None]), (0.6506608391085034, ['entropy', 'best', 2, 0.2959309501264299, 0.11852828211137273, 'balanced']), (0.6404581334158799, ['entropy', 'best', 3, 0.3483590146938983, 0.15805766259839937, None]), (0.5120032990662465, ['entropy', 'random', 2, 0.43127530609266995, 0.1247044307399302, 'balanced']), (0.5120032990662465, ['entropy', 'random', 4, 0.02330734031308529, 0.38677185655355717, 'balanced']), (0.6506608391085034, ['entropy', 'best', 3, 0.3047742823709143, 0.10011977362152424, None])]\n",
      "Parent 1 =  (0.6880424580228744, ['gini', 'best', 4, 0.1323130716702775, 0.1511691212720258, 'balanced'])\n",
      "Parent 2 =  (0.6506608391085034, ['entropy', 'best', 2, 0.3055614891036466, 0.068207406701416, None])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'kf_genetic_algorithm' object has no attribute 'crossover'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-04b148a90143>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Run Genetic Algorithm for N generations on given dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mbest_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mga\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-a857de3c801d>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;31m# Mate parents using one-point-crossover in order to generate offspring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[0moffspring1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffspring2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrossover\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparent1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparent2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;31m# Generate fitness_scores for the given population\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'kf_genetic_algorithm' object has no attribute 'crossover'"
     ]
    }
   ],
   "source": [
    "# Instantiate Genetic Algoritm class, which generates ga.population of size population_size\n",
    "# The population's chromosome genes depend upon the classifier being used\n",
    "# Different classifiers have different 'gene pools' (hyperparameter options)\n",
    "dataset_path = \"../Datasets/ISOT Botnet 2010/Pre-processed/isot_botnet.csv\"\n",
    "\n",
    "ga = kf_genetic_algorithm(classifier='DecisionTreeClassifier', dataset_path=dataset_path, population_size=10, generations=10)\n",
    "\n",
    "#print(\"\\nInital Population:\")\n",
    "#for chromosome in range(0, ga.population_size):\n",
    "#    print(ga.population[chromosome])\n",
    "\n",
    "# Run Genetic Algorithm for N generations on given dataset\n",
    "best_result = ga.run()\n",
    "\n",
    "\n",
    "del ga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
