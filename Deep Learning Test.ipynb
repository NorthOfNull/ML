{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T18:19:01.310476Z",
     "start_time": "2020-01-22T18:18:55.308340Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\asmarus\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\numpy\\lib\\arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "validation_size is not a legal parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-1292809ad1cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKerasClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmake_ffnn_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'precision_macro'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'recall_macro'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\asmarus\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, build_fn, **sk_params)\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_fn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msk_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msk_params\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msk_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\asmarus\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mcheck_params\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mparams_name\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'nb_epoch'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m                     raise ValueError(\n\u001b[1;32m---> 91\u001b[1;33m                         '{} is not a legal parameter'.format(params_name))\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: validation_size is not a legal parameter"
     ]
    }
   ],
   "source": [
    "# Test a deep learning model and evaluate precision, recall and f1 score for the model\n",
    "import kf_ml_lib as kf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import models\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def precision(y_true, y_pred):\t\n",
    "    \"\"\"Precision metric.\t\n",
    "    Only computes a batch-wise average of precision. Computes the precision, a\n",
    "    metric for multi-label classification of how many selected items are\n",
    "    relevant.\n",
    "    \"\"\"\t\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\t\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\t\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\t\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\t\n",
    "    \"\"\"Recall metric.\t\n",
    "    Only computes a batch-wise average of recall. Computes the recall, a metric\n",
    "    for multi-label classification of how many relevant items are selected.\t\n",
    "    \"\"\"\t\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\t\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\t\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\t\n",
    "    return recall\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    return (2 * p * r) / (p + r + K.epsilon())\n",
    "\n",
    "\n",
    "dataset_path = \"../Datasets/CTU-13/Pre-processed/1.csv\"\n",
    "dataset = kf.load_dataset(dataset_path)\n",
    "X, y = kf.split_dataset(dataset, extended=False)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, stratify=y)\n",
    "del dataset\n",
    "\n",
    "\n",
    "def make_ffnn_model():\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    model.add(Dense(5192, input_dim=6, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[precision, recall, f1_score])       \n",
    "    \n",
    "    return model\n",
    "              \n",
    "model = KerasClassifier(build_fn=make_ffnn_model, epochs=2, batch_size=500, verbose=1)\n",
    "\n",
    "scoring = ['precision_macro', 'recall_macro']\n",
    "                \n",
    "results = cross_validate(model, X, y, cv=10, scoring=scoring, n_jobs=1, verbose=0)\n",
    "\n",
    "\n",
    "fit_time = np.mean(results['fit_time'])\n",
    "precision = np.mean(results['test_precision_macro'])\n",
    "recall = np.mean(results['test_recall_macro'])\n",
    "f1_score = kf.calc_f1_score(precision, recall)\n",
    "\n",
    "print(fit_time)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid:\n",
    "    batch size = 500:\n",
    "        epochs = 2 :::: f1 =  0.6106146020685346\n",
    "        epochs = 5 :::: f1 =  0.6616933852796377\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T18:36:25.620395Z",
     "start_time": "2020-01-22T18:34:59.419489Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\asmarus\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\numpy\\lib\\arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1581796 samples, validate on 395449 samples\n",
      "Epoch 1/10\n",
      " - 7s - loss: 4.8464 - acc: 0.9811 - precision: 0.9843 - recall: 0.9954 - f1_score: 0.9897 - val_loss: 10.4322 - val_acc: 0.9857 - val_precision: 0.9857 - val_recall: 1.0000 - val_f1_score: 0.9928\n",
      "Epoch 2/10\n",
      " - 7s - loss: 2.6459 - acc: 0.9774 - precision: 0.9856 - recall: 0.9916 - f1_score: 0.9879 - val_loss: 0.3081 - val_acc: 0.9857 - val_precision: 0.9857 - val_recall: 1.0000 - val_f1_score: 0.9928\n",
      "Epoch 3/10\n",
      " - 7s - loss: 3.9901 - acc: 0.9786 - precision: 0.9856 - recall: 0.9928 - f1_score: 0.9888 - val_loss: 0.4121 - val_acc: 0.9857 - val_precision: 0.9857 - val_recall: 1.0000 - val_f1_score: 0.9928\n",
      "Epoch 4/10\n",
      " - 7s - loss: 3.4217 - acc: 0.9808 - precision: 0.9856 - recall: 0.9950 - f1_score: 0.9901 - val_loss: 2.7616 - val_acc: 0.9517 - val_precision: 0.9897 - val_recall: 0.9610 - val_f1_score: 0.9751\n",
      "Epoch 5/10\n",
      " - 7s - loss: 9.9258 - acc: 0.9751 - precision: 0.9858 - recall: 0.9891 - f1_score: 0.9867 - val_loss: 3.5758 - val_acc: 0.9857 - val_precision: 0.9857 - val_recall: 1.0000 - val_f1_score: 0.9928\n",
      "Epoch 6/10\n",
      " - 7s - loss: 4.8682 - acc: 0.9720 - precision: 0.9855 - recall: 0.9861 - f1_score: 0.9845 - val_loss: 8.6734 - val_acc: 0.9857 - val_precision: 0.9857 - val_recall: 1.0000 - val_f1_score: 0.9928\n",
      "Epoch 7/10\n",
      " - 7s - loss: 3.1547 - acc: 0.9759 - precision: 0.9856 - recall: 0.9901 - f1_score: 0.9873 - val_loss: 13.5710 - val_acc: 0.9857 - val_precision: 0.9857 - val_recall: 1.0000 - val_f1_score: 0.9928\n",
      "Epoch 8/10\n",
      " - 7s - loss: 6.0913 - acc: 0.9724 - precision: 0.9856 - recall: 0.9864 - f1_score: 0.9847 - val_loss: 14.4489 - val_acc: 0.9857 - val_precision: 0.9857 - val_recall: 1.0000 - val_f1_score: 0.9928\n",
      "Epoch 9/10\n",
      " - 7s - loss: 9.2768 - acc: 0.9743 - precision: 0.9856 - recall: 0.9883 - f1_score: 0.9860 - val_loss: 0.9937 - val_acc: 0.9853 - val_precision: 0.9857 - val_recall: 0.9996 - val_f1_score: 0.9926\n",
      "Epoch 10/10\n",
      " - 7s - loss: 32.9662 - acc: 0.9798 - precision: 0.9855 - recall: 0.9941 - f1_score: 0.9891 - val_loss: 61.6955 - val_acc: 0.9857 - val_precision: 0.9857 - val_recall: 1.0000 - val_f1_score: 0.9928\n",
      "['Normal']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test a deep learning model and evaluate precision, recall and f1 score for the model\n",
    "import kf_ml_lib as kf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import models, callbacks\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def precision(y_true, y_pred):\t\n",
    "    \"\"\"Precision metric.\t\n",
    "    Only computes a batch-wise average of precision. Computes the precision, a\n",
    "    metric for multi-label classification of how many selected items are\n",
    "    relevant.\n",
    "    \"\"\"\t\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\t\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\t\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\t\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\t\n",
    "    \"\"\"Recall metric.\t\n",
    "    Only computes a batch-wise average of recall. Computes the recall, a metric\n",
    "    for multi-label classification of how many relevant items are selected.\t\n",
    "    \"\"\"\t\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\t\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\t\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\t\n",
    "    return recall\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    return (2 * p * r) / (p + r + K.epsilon())\n",
    "\n",
    "\n",
    "\n",
    "def make_ffnn_model():\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    model.add(Dense(5196, input_dim=6, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc', precision, recall, f1_score])       \n",
    "    \n",
    "    return model\n",
    "\n",
    "dataset_path = \"../Datasets/CTU-13/Pre-processed/1.csv\"\n",
    "dataset = kf.load_dataset(dataset_path)\n",
    "X, y = kf.split_dataset(dataset, extended=False)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, stratify=y)\n",
    "del dataset\n",
    "    \n",
    "\n",
    "model = KerasClassifier(build_fn=make_ffnn_model, epochs=10, batch_size=2024, verbose=2)\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_split=0.2)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "unique = []\n",
    "\n",
    "for prediction in predictions:\n",
    "    if prediction[0] not in unique:\n",
    "        unique.append(prediction[0])\n",
    "\n",
    "print(unique)\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['f1_score'])\n",
    "plt.plot(history.history['val_f1_score'])\n",
    "plt.title('Model F1-Score')\n",
    "plt.ylabel('F1-Score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T18:58:18.225665Z",
     "start_time": "2020-01-22T18:58:16.181099Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "12288\n"
     ]
    }
   ],
   "source": [
    "pred = 0\n",
    "yc = 0\n",
    "\n",
    "for prediction in predictions:\n",
    "    if prediction == 'Botnet':\n",
    "        pred += 1\n",
    "for y in y_test:\n",
    "    if y == 'Botnet':\n",
    "        yc += 1\n",
    "        \n",
    "    \n",
    "print(pred)\n",
    "print(yc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T19:18:53.608631Z",
     "start_time": "2020-01-21T19:18:53.559763Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train botnet % of train set =  0.00828385427982098\n",
      "y_test botnet % of test set =  0.00828383310670579\n"
     ]
    }
   ],
   "source": [
    "y_train_botnet = 0\n",
    "for item in y_train:\n",
    "    if item == 'Botnet':\n",
    "        y_train_botnet += 1\n",
    "    \n",
    "y_test_botnet = 0\n",
    "for item in y_test:\n",
    "    if item == 'Botnet':\n",
    "        y_test_botnet += 1\n",
    "        \n",
    "print(\"y_train botnet % of train set = \", (y_train_botnet / len(y_train)))\n",
    "print(\"y_test botnet % of test set = \", (y_test_botnet / len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T02:42:10.971550Z",
     "start_time": "2020-02-06T01:07:24.759543Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\asmarus\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\numpy\\lib\\arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "4239574/4239574 [==============================] - 127s 30us/step - loss: 31.7784 - precision: 0.9983 - recall: 0.9984 - f1_score: 0.9983\n",
      "Epoch 2/4\n",
      "4239574/4239574 [==============================] - 126s 30us/step - loss: 3.8245 - precision: 0.9992 - recall: 0.9992 - f1_score: 0.9992\n",
      "Epoch 3/4\n",
      "4239574/4239574 [==============================] - 126s 30us/step - loss: 0.5263 - precision: 0.9994 - recall: 0.9994 - f1_score: 0.9994\n",
      "Epoch 4/4\n",
      "4239574/4239574 [==============================] - 127s 30us/step - loss: 0.1083 - precision: 0.9995 - recall: 0.9995 - f1_score: 0.9995\n",
      "471064/471064 [==============================] - 3s 7us/step\n",
      "Epoch 1/4\n",
      "4239574/4239574 [==============================] - 127s 30us/step - loss: 12.6965 - precision: 0.9982 - recall: 0.9983 - f1_score: 0.9983\n",
      "Epoch 2/4\n",
      "4239574/4239574 [==============================] - 127s 30us/step - loss: 1.9105 - precision: 0.9991 - recall: 0.9991 - f1_score: 0.9991\n",
      "Epoch 3/4\n",
      "4239574/4239574 [==============================] - 125s 29us/step - loss: 0.5635 - precision: 0.9993 - recall: 0.9993 - f1_score: 0.9993\n",
      "Epoch 4/4\n",
      "4239574/4239574 [==============================] - 130s 31us/step - loss: 0.2857 - precision: 0.9994 - recall: 0.9994 - f1_score: 0.9994\n",
      "471064/471064 [==============================] - 4s 7us/step\n",
      "Epoch 1/4\n",
      "4239574/4239574 [==============================] - 129s 30us/step - loss: 10.2542 - precision: 0.9983 - recall: 0.9984 - f1_score: 0.9983\n",
      "Epoch 2/4\n",
      "4239574/4239574 [==============================] - 129s 31us/step - loss: 0.4034 - precision: 0.9992 - recall: 0.9992 - f1_score: 0.9992\n",
      "Epoch 3/4\n",
      "4239574/4239574 [==============================] - 130s 31us/step - loss: 0.0717 - precision: 0.9995 - recall: 0.9992 - f1_score: 0.9994\n",
      "Epoch 4/4\n",
      "4239574/4239574 [==============================] - 129s 30us/step - loss: 0.0170 - precision: 0.9997 - recall: 0.9991 - f1_score: 0.9994\n",
      "471064/471064 [==============================] - 4s 8us/step\n",
      "Epoch 1/4\n",
      "4239574/4239574 [==============================] - 129s 30us/step - loss: 5.8104 - precision: 0.9983 - recall: 0.9984 - f1_score: 0.9984\n",
      "Epoch 2/4\n",
      "4239574/4239574 [==============================] - 139s 33us/step - loss: 0.2158 - precision: 0.9991 - recall: 0.9991 - f1_score: 0.9991\n",
      "Epoch 3/4\n",
      "4239574/4239574 [==============================] - 142s 34us/step - loss: 0.0219 - precision: 0.9997 - recall: 0.9988 - f1_score: 0.9992\n",
      "Epoch 4/4\n",
      "4239574/4239574 [==============================] - 161s 38us/step - loss: 0.0157 - precision: 0.9996 - recall: 0.9992 - f1_score: 0.9994\n",
      "471064/471064 [==============================] - 5s 10us/step\n",
      "Epoch 1/4\n",
      "4239574/4239574 [==============================] - 155s 37us/step - loss: 12.4693 - precision: 0.9984 - recall: 0.9984 - f1_score: 0.9984\n",
      "Epoch 2/4\n",
      "4239574/4239574 [==============================] - 170s 40us/step - loss: 1.0605 - precision: 0.9991 - recall: 0.9991 - f1_score: 0.9991\n",
      "Epoch 3/4\n",
      "4239574/4239574 [==============================] - 172s 41us/step - loss: 0.3236 - precision: 0.9993 - recall: 0.9993 - f1_score: 0.9993\n",
      "Epoch 4/4\n",
      "4239574/4239574 [==============================] - 159s 38us/step - loss: 0.0705 - precision: 0.9995 - recall: 0.9993 - f1_score: 0.9994\n",
      "471064/471064 [==============================] - 4s 9us/step\n",
      "Epoch 1/4\n",
      "4239574/4239574 [==============================] - 135s 32us/step - loss: 15.1561 - precision: 0.9982 - recall: 0.9984 - f1_score: 0.9983\n",
      "Epoch 2/4\n",
      "4239574/4239574 [==============================] - 132s 31us/step - loss: 0.3346 - precision: 0.9992 - recall: 0.9992 - f1_score: 0.9992\n",
      "Epoch 3/4\n",
      "4239574/4239574 [==============================] - 138s 32us/step - loss: 0.0556 - precision: 0.9995 - recall: 0.9993 - f1_score: 0.9994\n",
      "Epoch 4/4\n",
      "4239574/4239574 [==============================] - 141s 33us/step - loss: 0.0200 - precision: 0.9997 - recall: 0.9992 - f1_score: 0.9994\n",
      "471064/471064 [==============================] - 4s 9us/step\n",
      "Epoch 1/4\n",
      "4239574/4239574 [==============================] - 147s 35us/step - loss: 12.0081 - precision: 0.9983 - recall: 0.9984 - f1_score: 0.9983\n",
      "Epoch 2/4\n",
      "4239574/4239574 [==============================] - 155s 37us/step - loss: 1.8987 - precision: 0.9991 - recall: 0.9991 - f1_score: 0.9991\n",
      "Epoch 3/4\n",
      "4239574/4239574 [==============================] - 154s 36us/step - loss: 0.3912 - precision: 0.9994 - recall: 0.9993 - f1_score: 0.9993\n",
      "Epoch 4/4\n",
      "4239574/4239574 [==============================] - 132s 31us/step - loss: 0.0529 - precision: 0.9995 - recall: 0.9993 - f1_score: 0.9994\n",
      "471064/471064 [==============================] - 3s 7us/step\n",
      "Epoch 1/4\n",
      "4239574/4239574 [==============================] - 129s 30us/step - loss: 6.8290 - precision: 0.9986 - recall: 0.9986 - f1_score: 0.9986\n",
      "Epoch 2/4\n",
      "4239574/4239574 [==============================] - 141s 33us/step - loss: 0.1554 - precision: 0.9993 - recall: 0.9992 - f1_score: 0.9992\n",
      "Epoch 3/4\n",
      "4239574/4239574 [==============================] - 130s 31us/step - loss: 0.0159 - precision: 0.9997 - recall: 0.9992 - f1_score: 0.9995\n",
      "Epoch 4/4\n",
      "4239574/4239574 [==============================] - 130s 31us/step - loss: 0.0126 - precision: 0.9998 - recall: 0.9994 - f1_score: 0.9996\n",
      "471064/471064 [==============================] - 4s 8us/step\n",
      "Epoch 1/4\n",
      "4239575/4239575 [==============================] - 139s 33us/step - loss: 18.8297 - precision: 0.9985 - recall: 0.9986 - f1_score: 0.9985\n",
      "Epoch 2/4\n",
      "4239575/4239575 [==============================] - 141s 33us/step - loss: 3.0967 - precision: 0.9992 - recall: 0.9993 - f1_score: 0.9993\n",
      "Epoch 3/4\n",
      "4239575/4239575 [==============================] - 127s 30us/step - loss: 1.0845 - precision: 0.9994 - recall: 0.9994 - f1_score: 0.9994\n",
      "Epoch 4/4\n",
      "4239575/4239575 [==============================] - 126s 30us/step - loss: 0.4363 - precision: 0.9995 - recall: 0.9995 - f1_score: 0.9995\n",
      "471063/471063 [==============================] - 3s 7us/step\n",
      "Epoch 1/4\n",
      "4239575/4239575 [==============================] - 127s 30us/step - loss: 9.8039 - precision: 0.9985 - recall: 0.9986 - f1_score: 0.9986\n",
      "Epoch 2/4\n",
      "4239575/4239575 [==============================] - 129s 30us/step - loss: 0.1963 - precision: 0.9994 - recall: 0.9994 - f1_score: 0.9994\n",
      "Epoch 3/4\n",
      "4239575/4239575 [==============================] - 128s 30us/step - loss: 0.0288 - precision: 0.9997 - recall: 0.9993 - f1_score: 0.9995\n",
      "Epoch 4/4\n",
      "4239575/4239575 [==============================] - 145s 34us/step - loss: 0.0157 - precision: 0.9998 - recall: 0.9994 - f1_score: 0.9996\n",
      "471063/471063 [==============================] - 4s 9us/step\n",
      "\n",
      "\n",
      "\n",
      "test_precision_macro results =  [0.53702748 0.53614352 0.57894631 0.98526968 0.99265086 0.49999257\n",
      " 0.50880282 0.98669874 0.99532932 0.86266603]\n",
      "553.6836472511292\n",
      "0.7483527316435898\n",
      "0.9054869001977753\n",
      "0.819455021132894\n"
     ]
    }
   ],
   "source": [
    "# Test a deep learning model and evaluate precision, recall and f1 score for the model\n",
    "import kf_ml_lib as kf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import models\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def precision(y_true, y_pred):\t\n",
    "    \"\"\"Precision metric.\t\n",
    "    Only computes a batch-wise average of precision. Computes the precision, a\n",
    "    metric for multi-label classification of how many selected items are\n",
    "    relevant.\n",
    "    \"\"\"\t\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\t\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\t\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\t\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\t\n",
    "    \"\"\"Recall metric.\t\n",
    "    Only computes a batch-wise average of recall. Computes the recall, a metric\n",
    "    for multi-label classification of how many relevant items are selected.\t\n",
    "    \"\"\"\t\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\t\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\t\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\t\n",
    "    return recall\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    return (2 * p * r) / (p + r + K.epsilon())\n",
    "\n",
    "\n",
    "dataset_path = \"../Datasets/CTU-13/Pre-processed_Extended/3.csv\"\n",
    "dataset = kf.load_dataset(dataset_path)\n",
    "\n",
    "feature_vector_columns = ['sTos','dTos','SrcWin','DstWin','sHops','dHops',\n",
    "                          'sTtl','dTtl','TcpRtt','SynAck','AckDat','SrcPkts',\n",
    "                          'DstPkts','SrcBytes','DstBytes','SAppBytes','DAppBytes',\n",
    "                          'Dur','TotPkts','TotBytes','TotAppByte','Rate','SrcRate','DstRate']\n",
    "\n",
    "label_vector_column = ['Label']\n",
    "\n",
    "X = dataset.loc[:, feature_vector_columns]\n",
    "y = dataset.loc[:, label_vector_column]\n",
    "y = np.ravel(y)\n",
    "\n",
    "del dataset\n",
    "\n",
    "\n",
    "def make_ffnn_model():\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    model.add(Dense(5192, input_dim=24, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[precision, recall, f1_score])       \n",
    "    \n",
    "    return model\n",
    "              \n",
    "model = KerasClassifier(build_fn=make_ffnn_model, epochs=4, batch_size=100, verbose=1)\n",
    "\n",
    "scoring = ['precision_macro', 'recall_macro']\n",
    "                \n",
    "results = cross_validate(model, X, y, cv=10, scoring=scoring, n_jobs=1, verbose=0)\n",
    "\n",
    "print(\"\\n\\n\\ntest_precision_macro results = \", results['test_precision_macro'])\n",
    "\n",
    "fit_time = np.mean(results['fit_time'])\n",
    "precision = np.mean(results['test_precision_macro'])\n",
    "recall = np.mean(results['test_recall_macro'])\n",
    "f1_score = kf.calc_f1_score(precision, recall)\n",
    "\n",
    "print(fit_time)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "    # base dataset\n",
    "        # without sport dport\n",
    "        score = 0.5957670972341521\n",
    "        # with sport dport\n",
    "        score = 0.6820977367235456\n",
    "    # extended dataset\n",
    "        # without sport dport\n",
    "            # batch size = 100, epochs = 6\n",
    "            score = 0.8350587807579647\n",
    "        # with sport dport\n",
    "            # batch size = 100, epochs = 6\n",
    "            score = 0.8350587807579647\n",
    "            # batch size = 250, epochs = 4\n",
    "            score = 0.81939769947856\n",
    "            # batch size = 500, epochs = 2\n",
    "            score = 0.8079480571973956\n",
    "#3\n",
    "    # extended\n",
    "        #without sport dport\n",
    "            #batch size = 100, epochs = 4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
